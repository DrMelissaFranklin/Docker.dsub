{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30786,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrMelissaFranklin/Docker.dsub/blob/main/Mel_Project_6_from_Kaggle_working_but_needs_functions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project 6: Image Classification with Deep Learning\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9QpaA5HAyv_O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project introduces us to deep learning. The deep learning process is a huge leap forward in data science and the field is less than 15 years old. The processing is significantly different from our previous projects so you will basically be provided a walkthrough document delineating the steps - much like Project 1. Deep learning is fascinating and I just want you to go through the process so you can appreciate its power.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "aO3HLTWdzq3V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data collection portion of deep learning projects is a rather complex task. In other words, there is no CSV file that we can load to serve as our training data. Constructing a training data set is a rather large undertaking. We have imported all the training images (took hours) and I will show you how you can load the training data through the \"pickle\" process.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "4TMP83_Hzl9L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There are three files in this data set:\n",
        "\n",
        "- [the feature set]( https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/X.pickle ), i.e. images of dogs and cats ( mostly )\n",
        "\n",
        "- [the target set]( https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/y.pickle ), i.e. the indicator if something is a dog or cat ( mostly )\n",
        "\n",
        "- [a test image]( https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/dog.jpg )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ySPLD8gyzetb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project will classify new, unseen images of cats and dogs. This was one of the first big success stories of deep learning and we will go through the process of building a learning algorithm that will do this task. Telling a picture of a cat from a picture of a dog is easy for humans to do, but had been notoriously difficult to get a computer learning to perform well on the task. Deep learning solved that.\n"
      ],
      "metadata": {
        "id": "KGfC1Ukky06p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The same data set, but you can copy the links by viewing the markdown directly to bypass Google Colab's annoying \"You are leaving Colab\" link.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/X.pickle\n",
        "\n",
        "\n",
        "\n",
        "https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/y.pickle\n",
        "\n",
        "\n",
        "\n",
        "https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/dog.jpg\n"
      ],
      "metadata": {
        "id": "c2pMIDWq1B4L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Images â€“ To Do List\n"
      ],
      "metadata": {
        "id": "Z7IxnO3ZGqlL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "Prior to starting this problem, connect to a T4 or CPU to check code...?\n",
        "\n",
        "Be sure to enable the GPU runtime processing in your Jupyter notebook.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "09CQVfHpXRMB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem Definition\n"
      ],
      "metadata": {
        "id": "f5PuSqe-H8u5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Write a concise problem definition for the project. Put it in a text field at the top of your Jupyter notebook.\n",
        "\n",
        "\n",
        "\n",
        "* Load necessary packages.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nCOQv4YvXPBE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "import pickle #native to python for saving/loading using serialized data to be packed / unpacked\n",
        "\n",
        "\n",
        "\n",
        "import random\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "import cv2"
      ],
      "metadata": {
        "id": "0EUn8r4yCHf3"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras as keras # for nearest neighbors?\n",
        "\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "from keras.utils import plot_model\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import datasets # for algorithms.scaling"
      ],
      "metadata": {
        "id": "ZTGmmJGuJOMW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Collection from AWS S3 bucket.\n"
      ],
      "metadata": {
        "id": "Ll3rUMEKH_b9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url_X = \"https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/X.pickle\"\n",
        "\n",
        "\n",
        "\n",
        "url_y = \"https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/y.pickle\"\n",
        "\n",
        "\n",
        "\n",
        "url_dog = \"https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/dog.jpg\""
      ],
      "metadata": {
        "id": "nQTPStF_JO1N"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confirm connection to X and y pickle at AWS by comparing what get back from curl to url:"
      ],
      "metadata": {
        "id": "8izniMQnBpfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -0 https://www.google.com/url?q=https%3A%2F%2Fddc-datascience.s3.amazonahttps://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/X.pickle"
      ],
      "metadata": {
        "id": "0-A3kz3YDuXn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -0 https://ddc-datascience.s3.amazonaws.com/Projects/Project.6-Images/Data/y.pickle"
      ],
      "metadata": {
        "id": "fM6lYQLQBxPV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Read the pickled data from X.pickle and y.pickle\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DaGpv4TcXNpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.read_pickle(url_X)\n",
        "\n",
        "y = np.array(pd.read_pickle(url_y))"
      ],
      "metadata": {
        "id": "c_NYehZ4EBJ-"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Look at X and y data shapes and types"
      ],
      "metadata": {
        "id": "xEBTP2EVBZDk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm data shapes\n",
        "\n",
        "print(f\"X shape: {X.shape}\")\n",
        "\n",
        "print(f\"y shape: {y.shape}\")"
      ],
      "metadata": {
        "id": "vPoEK6Q__00I"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Confirm data types\n",
        "\n",
        "print(f\"X datatype: {type(X)}\")\n",
        "\n",
        "print(f\"y datatype: {type(y)}\")"
      ],
      "metadata": {
        "id": "XHVH3L0WAEKM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n"
      ],
      "metadata": {
        "id": "Qv-tmJlyIBrL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Scale the values in X so that they fall between 0 and 1 by dividing by 255.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DrJ-2JwDXMYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale X, but not y which is an array\n",
        "\n",
        "X_scaled = X/255\n",
        "\n",
        "X_scaled"
      ],
      "metadata": {
        "id": "EzDPOBMLJPnI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Exploratory Data Analysis\n"
      ],
      "metadata": {
        "id": "UDccpNdgIEHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Look at the shape of X and y. Ensure that X is 4 dimensional.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VRCwjqGZXLG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_scaled.shape"
      ],
      "metadata": {
        "id": "JP2pJKMBJQhk"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Plot a few ( >5 ) of the images in X using plt.imshow()."
      ],
      "metadata": {
        "id": "Hn74D-RFum66"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_scaled[0])"
      ],
      "metadata": {
        "id": "3LM0R4xAs4yF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_scaled[5])"
      ],
      "metadata": {
        "id": "eNGHyf6uvJQx"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_scaled[10])"
      ],
      "metadata": {
        "id": "r7DTltnwvJtu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_scaled[15])"
      ],
      "metadata": {
        "id": "BPVcnirTu4Mw"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow(X_scaled[20])"
      ],
      "metadata": {
        "id": "c1GMevq2vVxM"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#create a function for showing the same X images above\n",
        "\n",
        "for c in range(0, 20, 5): # reference the images using 'range'\n",
        "\n",
        "  plt.imshow(X_scaled[c]) # cycle through 'c'\n",
        "\n",
        "  plt.show() # display"
      ],
      "metadata": {
        "id": "20R023ZkxqWo"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Look at the response values in y for those images."
      ],
      "metadata": {
        "id": "mTqACdopupMP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y[0:21:5] #dogs 0, cats 1"
      ],
      "metadata": {
        "id": "oSzIDicEvlh8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Start with a random subset of 10% to get familiar with the process of building a NN before going through the process again with the full set."
      ],
      "metadata": {
        "id": "tUjbUbQLxpNi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Take a sample\n",
        "\n",
        "sample_size = int(0.1 * len(X_scaled))\n",
        "\n",
        "X_sample = X_scaled[:sample_size]\n",
        "\n",
        "y_sample = y[:sample_size]"
      ],
      "metadata": {
        "id": "-FMKaTwrBJ_H"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle the sample\n",
        "\n",
        "random.shuffle(X_sample)"
      ],
      "metadata": {
        "id": "sYjJuCHKBQSv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Processing\n"
      ],
      "metadata": {
        "id": "1swvVYT3IGoH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Split X and y into training and testing sets.\n"
      ],
      "metadata": {
        "id": "-MRKZ22_XI90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Another way to split the data, without randomization ...\n",
        "\n",
        "# X = X_scaled[:1000]\n",
        "\n",
        "# y = y_scaled[:1000]"
      ],
      "metadata": {
        "id": "iWlcAF8KdmnA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X = X_sample\n",
        "\n",
        "y = y_sample"
      ],
      "metadata": {
        "id": "1ePtaszRi8A8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42)"
      ],
      "metadata": {
        "id": "FU2fm8KtJRbW"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape training data\n",
        "\n",
        "X_train_reshaped = X_train.reshape(-1, 100, 100, 1)\n",
        "\n",
        "X_test_reshaped = X_test.reshape(-1, 100, 100, 1)\n",
        "\n",
        "\n",
        "\n",
        "print(\"X_train shape:\", X_train_reshaped.shape)\n",
        "\n",
        "print(\"X_test shape:\", X_test_reshaped.shape)\n"
      ],
      "metadata": {
        "id": "wmrVNE2IC5mU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize some samples\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "\n",
        "for i in range(5):\n",
        "\n",
        "    plt.subplot(1, 5, i+1)\n",
        "\n",
        "    plt.imshow(X_train_reshaped[i])\n",
        "\n",
        "    plt.title(f\"Label: {y_train[i]}\")\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HiP8MBWxDBUU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  Build a convolutional neural network with the following:\n",
        "\n",
        "  * Sequential layers\n",
        "\n",
        "  * At least two 2D convolutional layers using the 'relu' activation function and a (3,3) kernel size.\n",
        "\n",
        "  * A MaxPooling2D layer after each 2D convolutional layer that has a pool size of (2,2).\n",
        "\n",
        "  * A dense output layer using the 'sigmoid' activation function.\n",
        "\n",
        "  Note: you can play around with the number of layers and nodes to try to get better performance.\n",
        "\n",
        "\n",
        "\n",
        "* Compile your model. Use the 'adam' optimizer. Determine which loss function and metric is most appropriate for this problem.\n",
        "\n",
        "\n",
        "\n",
        "* Fit your model using the training set.\n",
        "\n",
        "\n",
        "\n",
        "* Evaluate your model using the testing set.\n",
        "\n",
        "\n",
        "\n",
        "* Plot the distribution of probabilities for the testing set.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "f3fS1YQLyEmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "\n",
        "    Conv2D(filters=32, kernel_size=(3, 3), activation='relu', input_shape=(100, 100, 1)),\n",
        "\n",
        "    MaxPooling2D(pool_size=(2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "\n",
        "    Dense(64, activation='relu'),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "model.compile(optimizer='adam',\n",
        "\n",
        "              loss='binary_crossentropy',\n",
        "\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "\n",
        "history = model.fit(X_train_reshaped, y_train, epochs=4, validation_data=(X_test_reshaped, y_test))\n",
        "\n",
        "\n",
        "\n",
        "# Evaluate the model\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test)\n",
        "\n",
        "print(f\"Test accuracy: {test_accuracy:.2f}\")\n"
      ],
      "metadata": {
        "id": "ydXZ3moaDTX_"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict probabilities for the entire test set\n",
        "\n",
        "predictions = model.predict(X_test_reshaped)\n",
        "\n",
        "\n",
        "\n",
        "# Plot the distribution of probabilities\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "plt.hist(predictions.flatten(), bins=50, edgecolor='black')\n",
        "\n",
        "plt.title('Distribution of Probabilities')\n",
        "\n",
        "plt.xlabel('Probability')\n",
        "\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.axvline(x=0.5, color='r', linestyle='dashed', linewidth=2, label='Decision Boundary')\n",
        "\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Plot ROC curve\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "\n",
        "\n",
        "fpr, tpr, _ = roc_curve(y_test, predictions.flatten())\n",
        "\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
        "\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "\n",
        "plt.xlim([0.0, 1.0])\n",
        "\n",
        "plt.ylim([0.0, 1.05])\n",
        "\n",
        "plt.xlabel('False Positive Rate')\n",
        "\n",
        "plt.ylabel('True Positive Rate')\n",
        "\n",
        "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "\n",
        "plt.legend(loc=\"lower right\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "# Print some statistics\n",
        "\n",
        "print(\"Mean prediction:\", np.mean(predictions))\n",
        "\n",
        "print(\"Standard deviation of predictions:\", np.std(predictions))\n"
      ],
      "metadata": {
        "id": "wavHi6WkEOtL"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "* Define a function that will read in a new image and convert it to a 4 dimensional array of pixels (ask the instructor for help with this). Hint: [numpy.reshape]( https://numpy.org/doc/stable/reference/generated/numpy.reshape.html )\n",
        "\n",
        "\n",
        "\n",
        "* Use the function defined above to read in the dog.jpg image that is saved in the AWS S3 bucket.\n",
        "\n",
        "\n",
        "\n",
        "* Use the neural network you created to predict whether the image is a dog or a cat."
      ],
      "metadata": {
        "id": "xIy4bwJKDkoS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Communication of Results\n"
      ],
      "metadata": {
        "id": "tT_-Jy7ZIJ3t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Communicate the results of your analysis.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MzKXfsuvXX7T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BONUS** (optional)\n"
      ],
      "metadata": {
        "id": "ztu8gpNSILmj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* Upload an image of your (or your friend's or family's) dog or cat and use your model to predict whether the image is a dog or cat.\n",
        "\n",
        "* Hint: you'll probably need to convert the image from color to grayscale.  OpenCV, pillow, and other libraries are your friend."
      ],
      "metadata": {
        "id": "DjGDKT60XY-G"
      }
    }
  ]
}